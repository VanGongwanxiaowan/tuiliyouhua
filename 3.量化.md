<img width="375" height="340" alt="image" src="https://github.com/user-attachments/assets/fa7f5717-1b87-4b42-9ac3-42481158c9b0" />

高比特到低比特的

<img width="458" height="462" alt="image" src="https://github.com/user-attachments/assets/d92b66eb-1a6b-4729-a19b-93c52d732006" />


# 7.5 量化
## 一、量化分类维度
- **QAT vs. PTQ**
- **对称量化vs非对称量化**：原点是否为0，即公式中\( z \)是否为0（\( s \)为量化数值间隔），量化公式为\( q = \text{clip}(\text{round}(\frac{r}{s} + z), q_{\text{min}}, q_{\text{max}}) \)
- **线性量化vs非线性量化**：数据范围是否均衡
- **动态量化vs静态量化**：
  - 静态量化的模型在使用前有“calibrate”过程（校准缩放因子），模型的缩放因子会根据输入数据的分布进行调整；
  - 动态量化仅将模型中特定算子的权重从FP32类型映射成INT8/16类型，bias和激活函数在推理过程中动态量化，且对于不同输入，其缩放因子是动态计算的
- **Weights量化vsActivation量化**：
  - per-token量化为activation量化，激活每个token对应的tensor共享量化系数，也可对整个activation进行量化（即Activation的per-tensor量化）；
  - Weight量化即对权重进行量化，根据量化粒度可细分为per-layer/tensor、per-group、per-channel
- **per-layer/tensor vs. per group vs. per channel**

## 二、几种主流的weight+activation量化方法
| Method         | Weight          | Activation      |
|----------------|-----------------|-----------------|
| W4A8           | per tensor      | per token dynamic |
| ZeroQuant      | group wise      | per token dynamic |
| LLM.int8()     | per-layer       | per-token dynamic + LP is |
| Outlier suppression | per tensor    | per token static |
| SmoothQuant-Q1 | per tensor      | per-token dynamic |
| SmoothQuant-Q2 | per tensor      | per-tensor dynamic |
| SmoothQuant-Q3 | per tensor      | per tensor static |

## 三、执行weight+activation量化策略的原因
1. 混合精度计算的链条更长，时间损耗大；
2. activation量化可以和normalization融合；
3. 输出格式的选择更多样。

## 四、主流算法（量化GEMM流程）
包含量化激活、量化权重、量化GEMM计算、反量化等环节，涉及不同精度数据的转换与计算流程。

<img width="786" height="594" alt="image" src="https://github.com/user-attachments/assets/cf429a29-4190-43b1-97e7-5269ea4967b0" />

# 量化策略分类与核心概念
## 一、QAT vs. PTQ
- **量化感知训练（Quantization-Aware Training, QAT）**：
  在模型训练过程中加入伪量化算子，通过训练时统计输入输出的数据范围提升量化后模型精度，适用于对模型精度要求较高的场景。其量化目标无缝集成到训练过程，使LLM在训练中适应低精度表示，增强处理量化精度损失的能力，部分文献称为在线量化，也有针对微调阶段单独定义QAF的情况。
- **训练后量化（Post Training Quantization, PTQ）**：
  在LLM训练完成后对其参数进行量化，仅需少量校准数据，适用于追求易用性和缺乏训练资源的场景。主要目标是减少存储和计算复杂性，无需修改LLM架构或重新训练，优势是简单高效，但可能引入一定精度损失，部分文献称为离线量化（部分文献中“在线vs.离线”指量化出发点是否为已量化好的checkpoint）。

## 二、量化分类维度
- **对称量化vs非对称量化**：
  原点是否为0，即量化公式\( q = \text{clip}(\text{round}(\frac{r}{s} + z), q_{\text{min}}, q_{\text{max}}) \)中\( z \)是否为0（\( s \)为量化数值间隔）。
- **线性量化vs非线性量化**：
  数据范围是否均衡。
- **动态量化vs静态量化**：
  - 静态量化：模型使用前有“calibrate”过程（校准缩放因子），缩放因子根据输入数据分布调整。
  - 动态量化：将模型中特定算子的权重从FP32映射为INT8/16类型，bias和激活函数在推理过程中动态量化，不同输入的缩放因子动态计算。
- **Weights量化vsActivation量化**：
  - per-token量化（activation量化）：激活每个token对应的tensor共享量化系数，也可对整个activation进行per-tensor量化。
  - Weight量化：对权重进行量化，根据粒度可分为per-layer/tensor、per-group、per-channel。

## 三、大模型推理优化策略关联
- **7.1 显存优化**
- **7.2 算子融合**
- **7.3 高性能算子**
- **7.4 调度优化**

<img width="731" height="761" alt="image" src="https://github.com/user-attachments/assets/46be9db8-fcd6-404e-a18d-56b4fbd5da04" />


<img width="925" height="761" alt="image" src="https://github.com/user-attachments/assets/71209409-ba6a-46f1-9faa-f85a9b34f491" />


<img width="473" height="203" alt="image" src="https://github.com/user-attachments/assets/f4928812-8ecb-487f-ba51-3857ae9a7af9" />

<img width="643" height="328" alt="image" src="https://github.com/user-attachments/assets/9f3553ae-355d-47d1-81d8-dea48b8b99ff" />


<img width="573" height="337" alt="image" src="https://github.com/user-attachments/assets/655df5da-c9c4-4cf6-92d0-cdb839fe33b5" />

<img width="475" height="189" alt="image" src="https://github.com/user-attachments/assets/97293741-e46e-49ed-9801-3aca947ee756" />


<img width="973" height="499" alt="image" src="https://github.com/user-attachments/assets/3d93fa08-49b4-4764-aa59-2f2f2baa468f" />

<img width="473" height="249" alt="image" src="https://github.com/user-attachments/assets/da082770-9d79-45b4-a5ba-68699d3070a3" />


<img width="636" height="111" alt="image" src="https://github.com/user-attachments/assets/56c638e8-876a-4b22-b2fd-55050fff19a9" />

<img width="638" height="570" alt="image" src="https://github.com/user-attachments/assets/2033425a-e777-4ccb-b9ee-026561003589" />

### 主流算法 - AWQ
#### AWQ 基础概念
1. AWQ 基于 smoothquant 提出，是一种 weight-only 量化；
2. AWQ 依据输入 \( X \) 及参数本身 \( W \) 的绝对大小把 \( s \) 分成 \( s_x \) 和 \( s_w \)，二者加权乘积作为最终 \( s \)，需满足 \( W \) 越大则 \( s \) 越小，\( X \) 越大则 \( s \) 越大。

#### AutoAWQ的实现逻辑
1. 模型类继承关系：每个模型（`models/auto.py`）是 `BaseAWQForCausalLM`（`models/base.py`）的子类，`BaseAWQForCausalLM` 定义 `quantize` 方法，调用 `AwqQuantizer` 类。`AwqQuantizer` 类定义 `quantize`、`pseudo_quantize_tensor`、`pseudo_dequantize_tensor`、`init_quant` 等方法，还有 `_apply_quant`（对 `module` 执行伪量化）、`_search_best_scale`（基于校准集 \( a_{PTQ} \) 权重 \( w \) 计算量化损失并得到每个 `channel` 的 `scale` 因子）、`_search_best_clip`（基于 \( a_{PTQ} \) 计算线性输入、基于 \( w \) 计算最大值作为 `clip`）、`_get_input_feat`、`_sanitize_kwargs`（删除前向过程不支持的参数）等私有方法。
2. 量化流程关键步骤：
   - `init_quant` 用于准备模型各 `module`、模型的 `layer_kwargs`、校准样本 `inputs`；
   - `pseudo_quantize_tensor` 执行标准非对称、均匀、per-group 量化；
   - `quantize` 先获取待量化层，过滤无需量化的层，获取 `input_feat` 计算 `scale_list`，对每个 `module` 应用 `scale_list` 计算 `clip_list`，针对每个 `module` 应用 `clip_list`，每个层调用 `_apply_quant`；
   - `_apply_quant` 调用 `pseudo_quantize_tensor` 执行一次非对称、均匀、per-group 量化，`clip_list`、`scale_list` 保留到每个量化后的层中。
3. 量化模块替换：`BaseAWQForCausalLM` 定义 `from_quantized` 方法，调用 `_load_quantized_modules` 将所有待量化的 `nn.Linear` 替换为 `WQLinear`（包括 `WQLinear_GEMM`、`WQLinear_GEMV`），然后调用 `WQLinear` 的 `from_linear` 方法初始化 `WQLinear` 类。
4. 计算执行：`WQLinear` 初始化时会注册 `qweight`、`qzeros`、`scales`、`bias` 等缓存，前向过程调用 `awq_ext` 库的 `gemm_forward_cuda` 方法执行计算，`awq_ext` 是由 C++ 编写的算子库，执行时进行反量化和 GEMM 或 GEMV 计算。

### 其他主流算法
- SpQR
- LLM.int8
- ZeroQuant

<img width="647" height="552" alt="image" src="https://github.com/user-attachments/assets/d0d46bab-5d19-4a85-9214-9299d269dbd2" />

<img width="696" height="520" alt="image" src="https://github.com/user-attachments/assets/16eb891d-93ac-423b-a59d-f325c147b960" />


<img width="669" height="589" alt="image" src="https://github.com/user-attachments/assets/2a5c3c9b-14a6-4976-98b4-ec5b323e15e8" />


<img width="728" height="471" alt="image" src="https://github.com/user-attachments/assets/4ee35835-8e0d-40f7-a78d-3436ea872538" />







